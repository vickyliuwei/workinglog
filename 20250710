## calculate diff genotype counts for related individuals to identify id's ecotype in 1001g ara 多线程python脚本计算
#!/usr/bin/env python3
import gzip
import sys
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
import multiprocessing

def load_relationships(relationship_file):
    """加载亲缘关系表，返回{id: [related_ids]}字典"""
    relationships = defaultdict(list)
    with open(relationship_file, 'r') as f:
        for line in f:
            id1, id2 = line.strip().split()
            relationships[id1].append(id2)
            relationships[id2].append(id1)
    return relationships

def compute_differences(vcf_file, target_ids, relationships):
    """多线程计算差异"""
    # 收集所有需要分析的ID
    all_ids = set(target_ids)
    for id in target_ids:
        all_ids.update(relationships.get(id, []))
    
    # 读取VCF数据
    samples = []
    id_indices = {}
    genotype_data = []
    
    with gzip.open(vcf_file, 'rt') as f:
        for line in f:
            if line.startswith('#CHROM'):
                samples = line.strip().split('\t')[10:]
                id_indices = {id: i for i, id in enumerate(samples) if id in all_ids}
                continue
            
            if not line.startswith('#'):
                fields = line.strip().split('\t')
                gts = [fields[i+10].split(':')[0].replace('|', '/') 
                      for i in range(len(samples)) if samples[i] in all_ids]
                genotype_data.append(gts)
    
    # 准备多线程任务
    def calculate_pair_diff(args):
        """计算单个ID对的差异"""
        target_id, related_id, target_idx, related_idx = args
        diff_count = 0
        for gts in genotype_data:
            gt1 = gts[target_idx]
            gt2 = gts[related_idx]
            if gt1 in ('./.', '.') or gt2 in ('./.', '.'):
                continue
            if gt1 != gt2:
                diff_count += 1
        return (target_id, related_id, diff_count)
    
    # 创建任务列表
    tasks = []
    for target_id in target_ids:
        if target_id not in id_indices:
            print(f"Warning: Target ID {target_id} not found in VCF", file=sys.stderr)
            continue
            
        related_ids = relationships.get(target_id, [])
        for related_id in related_ids:
            if related_id in id_indices:
                tasks.append((
                    target_id, 
                    related_id,
                    id_indices[target_id],
                    id_indices[related_id]
                ))
    
    # 多线程执行
    results = []
    with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:
        futures = [executor.submit(calculate_pair_diff, task) for task in tasks]
        for future in futures:
            try:
                results.append(future.result())
            except Exception as e:
                print(f"Error processing: {e}", file=sys.stderr)
    
    return results

def main():
    if len(sys.argv) != 4:
        print("Usage: python script.py <target_ids.list> <relationships.txt> <input.vcf.gz>")
        sys.exit(1)
    
    target_file = sys.argv[1]
    relationship_file = sys.argv[2]
    vcf_file = sys.argv[3]
    
    # 加载数据
    with open(target_file, 'r') as f:
        target_ids = [line.strip() for line in f]
    
    relationships = load_relationships(relationship_file)
    
    # 计算差异
    results = compute_differences(vcf_file, target_ids, relationships)
    
    # 输出结果
    print("Target_ID\tRelated_ID\tDiff_Count")
    for target_id, related_id, diff_count in sorted(results, key=lambda x: (x[0], x[2])):
        print(f"{target_id}\t{related_id}\t{diff_count}")

if __name__ == '__main__':
    main()
  # 运行命令（建议使用Python 3.7+）
python script.py target_ids.list relationships.txt input.vcf.gz > results.tsv
##################################################################################################################################
#统计vcf中不同物种共享或者独有的位点
#!/usr/bin/env python3
import gzip
import sys
from collections import defaultdict

def load_species_mapping(mapping_file):
    """加载ID到物种的映射"""
    id_to_species = {}
    species_ids = defaultdict(list)
    with open(mapping_file, 'r') as f:
        for line in f:
            id, species = line.strip().split()
            id_to_species[id] = species
            species_ids[species].append(id)
    return id_to_species, species_ids

def calculate_genotype_freq(genotypes):
    """计算基因型频率（忽略缺失数据）"""
    gt_counts = defaultdict(int)
    total = 0
    for gt in genotypes:
        if gt not in ('./.', '.'):
            gt_counts[gt] += 1
            total += 1
    return {gt: count/total for gt, count in gt_counts.items()} if total > 0 else {}

def analyze_vcf(vcf_file, id_to_species, species_ids):
    """分析VCF中的位点共享模式"""
    species_list = sorted(species_ids.keys())
    if len(species_list) != 4:
        raise ValueError("必须包含4个物种")
    
    results = {
        'unique': {s: 0 for s in species_list},
        'shared': defaultdict(int),
        'all_shared': 0
    }
    
    with gzip.open(vcf_file, 'rt') as f:
        # 读取样本头信息
        for line in f:
            if line.startswith('#CHROM'):
                samples = line.strip().split('\t')[9:]
                # 创建样本索引
                species_indices = {s: [i for i, id in enumerate(samples) if id in species_ids[s]] 
                                 for s in species_list}
                break
        
        # 处理每个变异位点
        for line in f:
            if not line.startswith('#'):
                fields = line.strip().split('\t')
                chrom, pos = fields[0], fields[1]
                variant_id = f"{chrom}:{pos}"
                gts = [fields[i+9].split(':')[0].replace('|', '/') for i in range(len(samples))]
                
                # 计算每个物种的基因型频率
                species_freq = {}
                for s in species_list:
                    s_gts = [gts[i] for i in species_indices[s]]
                    species_freq[s] = calculate_genotype_freq(s_gts)
                
                # 找出有数据的物种
                present_species = [s for s in species_list if species_freq[s]]
                if len(present_species) < 1:
                    continue
                
                # 比较频率差异
                if len(present_species) == 1:
                    results['unique'][present_species[0]] += 1
                else:
                    # 主物种与其他物种比较
                    main_species = present_species[0]
                    other_freq = {}
                    for s in present_species[1:]:
                        for gt, freq in species_freq[s].items():
                            other_freq[gt] = other_freq.get(gt, 0) + freq
                    # 标准化其他物种合并频率
                    other_total = sum(other_freq.values())
                    other_freq = {gt: f/other_total for gt, f in other_freq.items()}
                    
                    # 计算频率差异
                    diff_scores = []
                    for gt in set(species_freq[main_species]) | set(other_freq):
                        f1 = species_freq[main_species].get(gt, 0)
                        f2 = other_freq.get(gt, 0)
                        diff_scores.append(abs(f1 - f2))
                    
                    max_diff = max(diff_scores) if diff_scores else 0
                    
                    if max_diff == 1:  # 主物种特有
                        results['unique'][main_species] += 1
                    elif max_diff == 0:  # 全部共有
                        results['all_shared'] += 1
                    else:  # 部分共有
                        # 两两比较找出具体共享模式
                        shared_pairs = set()
                        for s1, s2 in itertools.combinations(present_species, 2):
                            diff = compare_species_freq(species_freq[s1], species_freq[s2])
                            if diff == 0:
                                shared_pairs.add(frozenset({s1, s2}))
                        
                        if len(shared_pairs) == 1:  # 仅一对物种共享
                            pair = tuple(sorted(next(iter(shared_pairs))))
                            results['shared'][pair] += 1
                        else:  # 更复杂的共享模式
                            results['shared']['complex'] += 1
    
    return results

def compare_species_freq(freq1, freq2):
    """比较两个物种的基因型频率差异"""
    all_gts = set(freq1.keys()) | set(freq2.keys())
    diffs = [abs(freq1.get(gt,0) - freq2.get(gt,0)) for gt in all_gts]
    return max(diffs) if diffs else 1

def generate_report(results, species_list):
    """生成分析报告"""
    print("=== 变异位点分类统计 ===")
    print(f"所有物种共有位点: {results['all_shared']}")
    
    print("\n=== 物种特有变异 ===")
    for s in species_list:
        print(f"{s}特有位点: {results['unique'][s]}")
    
    print("\n=== 两物种共有变异 ===")
    for pair in itertools.combinations(species_list, 2):
        print(f"{pair[0]}-{pair[1]}共有位点: {results['shared'].get(pair, 0)}")
    
    print(f"\n复杂共享模式位点: {results['shared'].get('complex', 0)}")

def main():
    if len(sys.argv) != 3:
        print("Usage: python script.py <id_species.map> <input.vcf.gz>")
        sys.exit(1)
    
    mapping_file = sys.argv[1]
    vcf_file = sys.argv[2]
    
    # 加载数据
    id_to_species, species_ids = load_species_mapping(mapping_file)
    species_list = sorted(species_ids.keys())
    print(f"分析物种: {', '.join(species_list)}")
    
    # 分析VCF
    results = analyze_vcf(vcf_file, id_to_species, species_ids)
    
    # 生成报告
    generate_report(results, species_list)

if __name__ == '__main__':
    import itertools
    main()
######################################################################################
#手动注释SNP位点所在的基因区域
#R
annotate_snps <- function(snp_data, annotation_data) {
  result <- matrix(data = NA,nrow = 49683,ncol = 5)
  result <- as.data.frame(result)
  result[,c(1:3)] <- snp_data
  for (i in 1:nrow(snp_data)) {
    snp <- snp_data[i, ]
    snp_chrom <- snp$V1
    snp_pos <- snp$V2
    categories <- c()
    eff <- c()
    p <- which(annotation_data[,"V1"] == snp_chrom & snp_pos >= annotation_data[,"V4"] & snp_pos <= annotation_data[,"V5"])
    if(length(p) != 0){
      annot_category <- annotation_data[p,"V3"]
      annot_eff <- annotation_data[p,"V9"]
      c <- paste(annot_category, collapse = ";")
      e <- paste(annot_eff, collapse = ";")
    } else{
      s <- max(which(annotation_data[,"V1"] == snp_chrom & snp_pos >= annotation_data[,"V5"]))
      e <- min(which(annotation_data[,"V1"] == snp_chrom & snp_pos <= annotation_data[,"V4"]))
      annot_category <- annotation_data[c(s,e),"V3"]
      annot_eff <- annotation_data[c(s,e),"V9"]
      c <- paste(annot_category, collapse = "-")
      e <- paste(annot_eff, collapse = "-")
    }
    categories <- c(categories,c)
    eff <- c(eff,e)
    result[i,4] <- categories
    result[i,5] <- eff
  }
  
  return(result)
}
#####统计不同类型
intron <- 0
noncodingexon <- 0
cds <- 0
three <- 0
five <- 0
for (i in c(1:nrow(gea_ann))){
  if(grepl(";",gea_ann[i,"V4"]) == T){
    v <- gea_ann[i,"V4"]
    if(grepl("exon",v) == F & grepl("mRNA",v) == T){
      intron <- intron + 1
    } else if(grepl("exon",v) == T & grepl("CDS",v) == F & grepl("three_prime_UTR",v) == F & grepl("five_prime_UTR",v) == F){
      noncodingexon <- noncodingexon + 1
    } else if(grepl("CDS",v) == T){
      cds <- cds + 1
    } else if(grepl("five_prime_UTR",v) == T){
      five <- five + 1
    } else if(grepl("three_prime_UTR",v) == T){
      three <- three + 1
    } else{
      print(i)
    }
  }
}
g <- vector()
for (i in c(1:nrow(gea_ann))){
  if(grepl(";",gea_ann[i,"V4"]) == T){
    v <- unlist(strsplit(gea_ann[i,"V5"], ";"))
    gene <- grep("Name=",v)
    t <- stringr::str_split_fixed(v[gene],"=",2)[,2]
    g <- append(g,t)
  }
}
p <- vector()
for (i in c(1:3046)){
  if(grepl(";",gea_ann[i,6]) == T){
    v <- unlist(strsplit(gea_ann[i,6], ";"))
    v <- unique(v)
    if(length(v) == 1){
      p <- append(p,i)
    }
  }
}
